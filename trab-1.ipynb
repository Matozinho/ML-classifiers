{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Classes:\n",
      "['bus' 'opel' 'saab' 'van']\n"
     ]
    }
   ],
   "source": [
    "dados = pd.read_csv(\"data/Vehicle.csv\")\n",
    "\n",
    "# transform the last collumn into integer values\n",
    "le = LabelEncoder()\n",
    "le.fit(dados[\"Class\"])\n",
    "dados[\"Class\"] = le.transform(dados[\"Class\"])\n",
    "\n",
    "df_dados = pd.DataFrame(dados)\n",
    "\n",
    "# print which class each integer value represents\n",
    "print(\"Encoded Classes:\")\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and split it into train, validation and test sets\n",
    "def ShuffleuSplit(df_dados):\n",
    "    # shuffle data to avoid bias\n",
    "    df_dados = shuffle(df_dados)\n",
    "\n",
    "    # separe the last column in another variable\n",
    "    df_dados_without_class = df_dados.drop(columns=[\"Class\"])\n",
    "\n",
    "    x_treino, x_temp, y_treino, y_temp = train_test_split(\n",
    "        df_dados_without_class,\n",
    "        df_dados[\"Class\"],\n",
    "        test_size=0.5,\n",
    "        stratify=df_dados[\"Class\"],\n",
    "    )\n",
    "    x_validacao, x_teste, y_validacao, y_teste = train_test_split(\n",
    "        x_temp, y_temp, test_size=0.5, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    # print(\"Treino\")\n",
    "    # x_treino.info()\n",
    "    # y_treino.info()\n",
    "\n",
    "    # print(\"\\nValidação\")\n",
    "    # x_validacao.info()\n",
    "    # y_validacao.info()\n",
    "\n",
    "    # print(\"\\nTeste\")\n",
    "    # x_teste.info()\n",
    "    # y_teste.info()\n",
    "    return (\n",
    "        x_treino,\n",
    "        y_treino,\n",
    "        x_validacao,\n",
    "        y_validacao,\n",
    "        x_teste,\n",
    "        y_teste,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Roc Curve\n",
    "def plot_roc_curve(fper, tper, cor, classsificador):\n",
    "    plt.clf()\n",
    "    plt.plot(fper, tper, color=cor, label=classsificador)\n",
    "    plt.plot([0, 1], [0, 1], color=\"green\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "    plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "    plt.title(\"Curva ROC\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def grid_search_KNN(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    best_accuracy = -1\n",
    "    best_k = -1\n",
    "    best_distance_metric = \"\"\n",
    "    best_KNN = None\n",
    "\n",
    "    for k in range(1, 50, 2):\n",
    "        for distance_metric in [\"uniform\", \"distance\"]:\n",
    "            knn_instance = KNeighborsClassifier(\n",
    "                n_jobs=-1, n_neighbors=k, weights=distance_metric\n",
    "            )\n",
    "            knn_instance.fit(x_treino, y_treino)\n",
    "            knn_validation_pred = knn_instance.predict(x_validacao)\n",
    "            accuracy = accuracy_score(y_validacao, knn_validation_pred)\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_k = k\n",
    "                best_distance_metric = distance_metric\n",
    "                best_KNN = knn_instance\n",
    "\n",
    "    return best_KNN, best_k, best_distance_metric\n",
    "\n",
    "\n",
    "def KNN(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_KNN, best_k, best_distance_metric = grid_search_KNN(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    knn_test_pred = best_KNN.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, knn_test_pred)\n",
    "\n",
    "    return test_accuracy, best_KNN, best_k, best_distance_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def grid_search_DT(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    param_grid = {\n",
    "        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"max_depth\": range(1, 33, 2),\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    best_DT = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        # print(f\"Testing parameters: {params}\")\n",
    "        DT = DecisionTreeClassifier(**params)\n",
    "        DT.fit(x_treino, y_treino)\n",
    "        dt_validation_pred = DT.predict(x_validacao)\n",
    "        accuracy = accuracy_score(y_validacao, dt_validation_pred)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            best_DT = DT\n",
    "\n",
    "    return best_DT, best_params\n",
    "\n",
    "\n",
    "def DT(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_DT, best_params = grid_search_DT(x_treino, y_treino, x_validacao, y_validacao)\n",
    "\n",
    "    dt_test_pred = best_DT.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, dt_test_pred)\n",
    "\n",
    "    return test_accuracy, best_DT, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def grid_search_SVM(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    param_grid = {\n",
    "        \"C\": [0.1, 1.0, 10.0],  # Define C values\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    }\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    best_SVM = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        SVM = SVC(**params, probability=True)\n",
    "        SVM.fit(x_treino, y_treino)\n",
    "        svm_validation_pred = SVM.predict(x_validacao)\n",
    "        accuracy = accuracy_score(y_validacao, svm_validation_pred)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            best_SVM = SVM\n",
    "\n",
    "    return best_SVM, best_params\n",
    "\n",
    "\n",
    "def SVM(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_SVM, best_params = grid_search_SVM(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    svm_test_pred = best_SVM.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, svm_test_pred)\n",
    "\n",
    "    return test_accuracy, best_SVM, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def NB(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    NB = GaussianNB()\n",
    "    NB.fit(x_treino, y_treino)\n",
    "\n",
    "    nb_predict_test = NB.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, nb_predict_test)\n",
    "\n",
    "    return test_accuracy, NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def grid_search_MLP(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    param_grid = {\n",
    "        \"hidden_layer_sizes\": [\n",
    "            (100,),\n",
    "            (50, 50),\n",
    "            (100, 50, 25),\n",
    "        ],  # Define hidden_layer_sizes\n",
    "        \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "        \"max_iter\": [1000, 2000],  # Define max_iter values\n",
    "        \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    }\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    best_MLP = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        MLP = MLPClassifier(**params)\n",
    "        MLP.fit(x_treino, y_treino)\n",
    "        mlp_validation_pred = MLP.predict(x_validacao)\n",
    "        accuracy = accuracy_score(y_validacao, mlp_validation_pred)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            best_MLP = MLP\n",
    "\n",
    "    return best_MLP, best_params\n",
    "\n",
    "\n",
    "def MLP(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_MLP, best_params = grid_search_MLP(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    mlp_test_pred = best_MLP.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, mlp_test_pred)\n",
    "\n",
    "    return test_accuracy, best_MLP, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borda Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BordaCountClassifier:\n",
    "    def __init__(self, estimators):\n",
    "        \"\"\"\n",
    "        Initialize the BordaCountClassifier.\n",
    "\n",
    "        Parameters:\n",
    "        - estimators: List of classifiers.\n",
    "        \"\"\"\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit each estimator to the data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Features.\n",
    "        - y: Target labels.\n",
    "        \"\"\"\n",
    "        for _, estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels using the Borda Count approach.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Features.\n",
    "\n",
    "        Returns:\n",
    "        - Predicted class labels.\n",
    "        \"\"\"\n",
    "        all_probs = [estimator.predict_proba(X) for _, estimator in self.estimators]\n",
    "        all_probs = np.stack(all_probs)\n",
    "\n",
    "        # Get rankings for each classifier's predictions\n",
    "        rankings = np.argsort(-all_probs, axis=-1)\n",
    "\n",
    "        # Assign points based on rankings\n",
    "        num_classes = all_probs.shape[2]\n",
    "        points = np.zeros_like(rankings)\n",
    "        for rank in range(num_classes):\n",
    "            points[rankings == rank] = num_classes - 1 - rank\n",
    "\n",
    "        # Sum points across classifiers\n",
    "        total_points = points.sum(axis=0)\n",
    "\n",
    "        # Get the final prediction as the class with the highest total points\n",
    "        final_predictions = np.argmax(total_points, axis=1)\n",
    "\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "['bus' 'opel' 'saab' 'van']\n",
      "============================================\n",
      "============================================\n",
      "0 : [0.6179245283018868, 0.6462264150943396, 0.419811320754717, 0.7405660377358491, 0.6745283018867925, 0.6839622641509434, 0.6698113207547169, 0.4339622641509434]\n",
      "============================================\n",
      "============================================\n",
      "1 : [0.5990566037735849, 0.6415094339622641, 0.41037735849056606, 0.7594339622641509, 0.6745283018867925, 0.7028301886792453, 0.7311320754716981, 0.44339622641509435]\n",
      "============================================\n",
      "============================================\n",
      "2 : [0.5849056603773585, 0.6320754716981132, 0.4858490566037736, 0.7877358490566038, 0.6226415094339622, 0.6792452830188679, 0.6886792452830188, 0.4056603773584906]\n",
      "============================================\n",
      "============================================\n",
      "3 : [0.6556603773584906, 0.7405660377358491, 0.419811320754717, 0.7924528301886793, 0.7122641509433962, 0.7735849056603774, 0.7641509433962265, 0.49528301886792453]\n",
      "============================================\n",
      "============================================\n",
      "4 : [0.5849056603773585, 0.7358490566037735, 0.4528301886792453, 0.7971698113207547, 0.6745283018867925, 0.7594339622641509, 0.7122641509433962, 0.4528301886792453]\n",
      "============================================\n",
      "============================================\n",
      "5 : [0.6415094339622641, 0.6886792452830188, 0.4481132075471698, 0.7877358490566038, 0.6933962264150944, 0.7405660377358491, 0.7169811320754716, 0.46226415094339623]\n",
      "============================================\n",
      "============================================\n",
      "6 : [0.6084905660377359, 0.7028301886792453, 0.42452830188679247, 0.7311320754716981, 0.5990566037735849, 0.6933962264150944, 0.7452830188679245, 0.4858490566037736]\n",
      "============================================\n",
      "============================================\n",
      "7 : [0.5660377358490566, 0.6839622641509434, 0.5188679245283019, 0.7783018867924528, 0.6698113207547169, 0.7264150943396226, 0.7028301886792453, 0.4811320754716981]\n",
      "============================================\n",
      "============================================\n",
      "8 : [0.5707547169811321, 0.6933962264150944, 0.42924528301886794, 0.8301886792452831, 0.6981132075471698, 0.6981132075471698, 0.75, 0.44339622641509435]\n",
      "============================================\n",
      "============================================\n",
      "9 : [0.6886792452830188, 0.7169811320754716, 0.5047169811320755, 0.7877358490566038, 0.6462264150943396, 0.7735849056603774, 0.7452830188679245, 0.419811320754717]\n",
      "============================================\n",
      "============================================\n",
      "10 : [0.6698113207547169, 0.7169811320754716, 0.4811320754716981, 0.8018867924528302, 0.6981132075471698, 0.7405660377358491, 0.7452830188679245, 0.4716981132075472]\n",
      "============================================\n",
      "============================================\n",
      "11 : [0.6745283018867925, 0.7216981132075472, 0.39622641509433965, 0.8160377358490566, 0.6933962264150944, 0.7783018867924528, 0.75, 0.4858490566037736]\n",
      "============================================\n",
      "============================================\n",
      "12 : [0.589622641509434, 0.7122641509433962, 0.4339622641509434, 0.7641509433962265, 0.6320754716981132, 0.7264150943396226, 0.7216981132075472, 0.4811320754716981]\n",
      "============================================\n",
      "============================================\n",
      "13 : [0.6179245283018868, 0.7028301886792453, 0.5, 0.7688679245283019, 0.7216981132075472, 0.7594339622641509, 0.6933962264150944, 0.4811320754716981]\n",
      "============================================\n",
      "============================================\n",
      "14 : [0.589622641509434, 0.6698113207547169, 0.4386792452830189, 0.7641509433962265, 0.6556603773584906, 0.7028301886792453, 0.7075471698113207, 0.45754716981132076]\n",
      "============================================\n",
      "============================================\n",
      "15 : [0.6132075471698113, 0.7169811320754716, 0.46226415094339623, 0.7688679245283019, 0.6981132075471698, 0.7216981132075472, 0.7169811320754716, 0.49528301886792453]\n",
      "============================================\n",
      "============================================\n",
      "16 : [0.6886792452830188, 0.7122641509433962, 0.4858490566037736, 0.8254716981132075, 0.6886792452830188, 0.7641509433962265, 0.7594339622641509, 0.49528301886792453]\n",
      "============================================\n",
      "============================================\n",
      "17 : [0.6320754716981132, 0.660377358490566, 0.47641509433962265, 0.8113207547169812, 0.6745283018867925, 0.7924528301886793, 0.7594339622641509, 0.5141509433962265]\n",
      "============================================\n",
      "============================================\n",
      "18 : [0.6509433962264151, 0.7028301886792453, 0.46226415094339623, 0.7405660377358491, 0.6556603773584906, 0.7311320754716981, 0.7075471698113207, 0.5]\n",
      "============================================\n",
      "============================================\n",
      "19 : [0.5990566037735849, 0.6886792452830188, 0.45754716981132076, 0.8066037735849056, 0.6745283018867925, 0.7405660377358491, 0.7169811320754716, 0.41037735849056606]\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "output = pd.DataFrame(columns=[\"KNN\", \"DT\", \"NB\", \"SVM\", \"MLP\", \"MV\", \"SV\", \"BC\"])\n",
    "\n",
    "knn_best_params = pd.DataFrame(columns=[\"K\", \"Distance Metric\"])\n",
    "dt_best_params = pd.DataFrame(\n",
    "    columns=[\"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"]\n",
    ")\n",
    "svm_best_params = pd.DataFrame(columns=[\"C\", \"kernel\"])\n",
    "mlp_best_params = pd.DataFrame(\n",
    "    columns=[\"hidden_layer_sizes\", \"activation\", \"max_iter\", \"learning_rate\"]\n",
    ")\n",
    "\n",
    "## find the number of elements of each class in the dataset\n",
    "print(\"============================================\")\n",
    "print(le.classes_)\n",
    "print(\"============================================\")\n",
    "\n",
    "for i in range(20):\n",
    "    shuffled_data = ShuffleuSplit(df_dados)\n",
    "\n",
    "    # KNN Execution\n",
    "    knn_accuracy, knn_model, *knn_params = KNN(*shuffled_data)\n",
    "    knn_best_params.loc[len(knn_best_params.index)] = knn_params\n",
    "\n",
    "    # # show confusion matrix for KNN\n",
    "    # knn_test_pred = knn_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nKNN Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", knn_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], knn_test_pred))\n",
    "\n",
    "    # DT Execution\n",
    "    dt_accuracy, dt_model, dt_params = DT(*shuffled_data)\n",
    "    dt_params = [\n",
    "        dt_params[key]\n",
    "        for key in [\"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"]\n",
    "    ]\n",
    "    dt_best_params.loc[len(dt_best_params.index)] = dt_params\n",
    "\n",
    "    # # show confusion matrix for DT\n",
    "    # dt_test_pred = dt_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nDT Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", dt_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], dt_test_pred))\n",
    "\n",
    "    # SVM Execution\n",
    "    svm_accuracy, svm_model, svm_params = SVM(*shuffled_data)\n",
    "    svm_params = [svm_params[key] for key in [\"C\", \"kernel\"]]\n",
    "    svm_best_params.loc[len(svm_best_params.index)] = svm_params\n",
    "\n",
    "    # # show confusion matrix for SVM\n",
    "    # svm_test_pred = svm_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nSVM Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", svm_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], svm_test_pred))\n",
    "\n",
    "    # NB Execution\n",
    "    nb_accuracy, nb_model = NB(*shuffled_data)\n",
    "\n",
    "    # # show confusion matrix for NB\n",
    "    # nb_test_pred = nb_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nNB Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", nb_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], nb_test_pred))\n",
    "\n",
    "    # MLP Execution\n",
    "    mlp_accuracy, mlp_model, mlp_params = MLP(*shuffled_data)\n",
    "    mlp_params = [\n",
    "        mlp_params[key]\n",
    "        for key in [\"hidden_layer_sizes\", \"activation\", \"max_iter\", \"learning_rate\"]\n",
    "    ]\n",
    "    mlp_best_params.loc[len(mlp_best_params.index)] = mlp_params\n",
    "\n",
    "    # # show confusion matrix for MLP\n",
    "    # mlp_test_pred = mlp_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nMLP Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", mlp_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], mlp_test_pred))\n",
    "\n",
    "    # create a multiple classifier approach with VotingClassifier\n",
    "    estimators = [\n",
    "        (\"knn\", knn_model),\n",
    "        (\"dt\", dt_model),\n",
    "        (\"nb\", nb_model),\n",
    "        (\"svm\", svm_model),\n",
    "        (\"mlp\", mlp_model),\n",
    "    ]\n",
    "\n",
    "    # majority voting\n",
    "    majority_voting_classifier = VotingClassifier(estimators=estimators, voting=\"hard\")\n",
    "    majority_voting_classifier.fit(shuffled_data[0], shuffled_data[1])\n",
    "\n",
    "    voting_test_pred = majority_voting_classifier.predict(shuffled_data[4])\n",
    "    majority_voting_accuracy = accuracy_score(shuffled_data[5], voting_test_pred)\n",
    "\n",
    "    # print(\"\\nMajority Rule Voting Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", majority_voting_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], voting_test_pred))\n",
    "\n",
    "    # sum voting\n",
    "    sum_voting_classifier = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "    sum_voting_classifier.fit(shuffled_data[0], shuffled_data[1])\n",
    "\n",
    "    voting_test_pred = sum_voting_classifier.predict(shuffled_data[4])\n",
    "    sum_voting_accuracy = accuracy_score(shuffled_data[5], voting_test_pred)\n",
    "\n",
    "    # print(\"\\nSum Rule Voting Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", sum_voting_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], voting_test_pred))\n",
    "\n",
    "    # borda count\n",
    "    borda_clf = BordaCountClassifier(estimators=estimators)\n",
    "    borda_clf.fit(shuffled_data[0], shuffled_data[1])\n",
    "    borda_count_predictions = borda_clf.predict(shuffled_data[4])\n",
    "    bc_accuracy = accuracy_score(shuffled_data[5], borda_count_predictions)\n",
    "\n",
    "    # print(\"\\nBorda Count Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", bc_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], borda_count_predictions))\n",
    "\n",
    "    # add accuracies to output\n",
    "    output.loc[len(output.index)] = [\n",
    "        knn_accuracy,\n",
    "        dt_accuracy,\n",
    "        nb_accuracy,\n",
    "        svm_accuracy,\n",
    "        mlp_accuracy,\n",
    "        majority_voting_accuracy,\n",
    "        sum_voting_accuracy,\n",
    "        bc_accuracy,\n",
    "    ]\n",
    "\n",
    "    # print current index and current line\n",
    "    print(\"============================================\")\n",
    "    print(\n",
    "        i,\n",
    "        \":\",\n",
    "        [\n",
    "            knn_accuracy,\n",
    "            dt_accuracy,\n",
    "            nb_accuracy,\n",
    "            svm_accuracy,\n",
    "            mlp_accuracy,\n",
    "            majority_voting_accuracy,\n",
    "            sum_voting_accuracy,\n",
    "            bc_accuracy,\n",
    "        ],\n",
    "    )\n",
    "    print(\"============================================\")\n",
    "\n",
    "\n",
    "# generate csv from knn best params, ignoring the index columns\n",
    "knn_best_params.to_csv(\"best_params/knn.csv\", index=False)\n",
    "dt_best_params.to_csv(\"best_params/dt.csv\", index=False)\n",
    "svm_best_params.to_csv(\"best_params/svm.csv\", index=False)\n",
    "mlp_best_params.to_csv(\"best_params/mlp.csv\", index=False)\n",
    "\n",
    "# generate csv from output, ignoring the index columns\n",
    "output.to_csv(\"output.csv\", inde x=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
